{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "\n",
        "Answer:\n",
        "A Decision Tree is a supervised learning algorithm used for classification and regression problems. For classification, it recursively splits the dataset into subsets based on feature values, forming a tree where each internal node is a decision (question about a feature) and each leaf node represents a class label. The algorithm asks the optimal sequence of questions, guiding data samples down branches to reach specific predictions.\n",
        "\n",
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Gini Impurity and Entropy are metrics used to evaluate the \"purity\" of a split in a Decision Tree.\n",
        "\n",
        "Gini Impurity quantifies the likelihood of misclassification if labels were assigned randomly (formula):\n",
        "\n",
        "Entropy measures the level of disorder (uncertainty) in a dataset:\n",
        "\n",
        "A split that creates subsets with lower impurity (fewer mixed labels) is preferred, improving the Decision Tree’s ability to classify new examples.\n",
        "\n",
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Pre-Pruning stops the tree from growing beyond a certain point (e.g., max depth, min samples) during training, preventing overfitting early. Advantage: Faster training and simpler, more interpretable trees.\n",
        "\n",
        "Post-Pruning allows the tree to grow fully and then removes branches that don’t improve accuracy via validation. Advantage: More carefully balances accuracy and complexity; often results in better generalization.\n",
        "\n",
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Information Gain is the reduction in impurity (e.g., entropy) by splitting a node on a specific feature. It's crucial because the tree always splits on the feature offering the highest information gain at each step, building the most effective structure for discrimination.\n",
        "\n",
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Applications: Medical diagnosis, credit risk assessment, marketing, fraud detection, customer segmentation, and more.\n",
        "Advantages: Easy to interpret and visualize, handles mixed data types, minimal data preprocessing required.\n",
        "Limitations: Can overfit easily, sensitive to small data changes, less effective for highly correlated data or complex decision boundaries.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gsuJE_3Sb3Vz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h84EH-zkZMUP",
        "outputId": "cdf30510-dd3c-4cdf-a8bb-394d2973035c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01333333 0.06405596 0.92261071]\n"
          ]
        }
      ],
      "source": [
        "#Question 6: Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Train a Decision Tree Classifier using the Gini criterion\n",
        "#● Print the model’s accuracy and feature importances\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "#Answer:\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='gini')\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(\"Accuracy:\", clf.score(X, y))\n",
        "print(\"Feature Importances:\", clf.feature_importances_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "#a fully-grown tree.\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "#Answer:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "clf_full = DecisionTreeClassifier()\n",
        "clf_full.fit(X_train, y_train)\n",
        "print(\"Full Tree Accuracy:\", clf_full.score(X_test, y_test))\n",
        "\n",
        "\n",
        "clf_depth3 = DecisionTreeClassifier(max_depth=3)\n",
        "clf_depth3.fit(X_train, y_train)\n",
        "print(\"Max Depth=3 Accuracy:\", clf_depth3.score(X_test, y_test))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZL9S0-lfYb",
        "outputId": "94d48f1d-2f9d-48b6-8b00-06c8b1742f08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tree Accuracy: 1.0\n",
            "Max Depth=3 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to:\n",
        "#● Load the California Housing dataset from sklearn\n",
        "#● Train a Decision Tree Regressor\n",
        "#● Print the Mean Squared Error (MSE) and feature importances\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "#Answer:\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X, y)\n",
        "\n",
        "\n",
        "y_pred = reg.predict(X)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y, y_pred))\n",
        "print(\"Feature Importances:\", reg.feature_importances_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J5xfEITmMAd",
        "outputId": "784b88dc-c88a-4e71-fde6-cc467ac81254"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.0070971343301193e-31\n",
            "Feature Importances: [0.52439443 0.05105658 0.05227414 0.02781658 0.03276769 0.13235599\n",
            " 0.0944909  0.08484369]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "#GridSearchCV\n",
        "#● Print the best parameters and the resulting model accuracy\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "#Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw3l0_FOm9bm",
        "outputId": "5ab37e62-628a-4bab-ff94-901c182bdeee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 5}\n",
            "Best Accuracy: 0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySKB-UBxn1jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to\n",
        "\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Handle Missing Values: Impute numerical features with mean/median; handle categorical missing values with mode or a new category.\n",
        "\n",
        "Encode Categorical Features: Use label or one-hot encoding for non-numeric features.\n",
        "\n",
        "Train Decision Tree: Fit the model using the processed dataset.\n",
        "\n",
        "Tune Hyperparameters: Use GridSearchCV to optimize parameters like max_depth and min_samples_split for best performance.\n",
        "\n",
        "Evaluate Performance: Use metrics such as accuracy, precision, recall, and the confusion matrix.\n",
        "Business Value: Enables automated, interpretable predictions that improve early disease detection, help target interventions, and optimize resource use, ultimately supporting better patient outcomes and operational efficiency in healthcare."
      ],
      "metadata": {
        "id": "1z0H8GFJoDIC"
      }
    }
  ]
}