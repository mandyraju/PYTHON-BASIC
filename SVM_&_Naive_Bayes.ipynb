{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Support Vector Machine (SVM), and how does it work?\n",
        "\n",
        "Answer:\n",
        "A Support Vector Machine is a supervised algorithm used for classification and regression. It works by finding the best separating boundary (hyperplane) between classes in the feature space and aims to maximize the margin—the distance between the hyperplane and the nearest data points from each class, called support vectors.\n",
        "\n",
        "Question 2: Explain the difference between Hard Margin and Soft Margin SVM.\n",
        "\n",
        "Answer:\n",
        "Hard Margin: Requires perfectly linearly separable data, finds a boundary with zero misclassifications, and is sensitive to outliers.\n",
        "\n",
        "Soft Margin: Allows some classification errors by introducing slack variables, balancing margin size and errors; it's robust to noisy and non-linearly separable data and controlled by a regularization parameter\n",
        "\n",
        "Question 3: What is the Kernel Trick in SVM? Give one example of a kernel and\n",
        "explain its use case.\n",
        "\n",
        "Answer:\n",
        "The kernel trick allows SVMs to handle non-linear data by implicitly mapping it into higher-dimensional space, where classes can be separated by a hyperplane.\n",
        "\n",
        "For example, the RBF (Radial Basis Function) kernel is used to capture complex boundaries—ideal when classes can't be separated by a straight line.\n",
        "\n",
        "Question 4: What is a Naïve Bayes Classifier, and why is it called “naïve”?\n",
        "\n",
        "Answer:\n",
        "Naïve Bayes is a probabilistic classifier based on Bayes’ theorem. It’s called “naïve” because it assumes all features are independent from each other, which rarely holds in real data, but often works surprisingly well.\n",
        "\n",
        "Question 5: Describe the Gaussian, Multinomial, and Bernoulli Naïve Bayes variants. When would you use each one?\n",
        "\n",
        "Answer:\n",
        "Gaussian: Assumes features are continuous and follow a normal (Gaussian) distribution. Use when input features are real values.\n",
        "\n",
        "Multinomial: Used for discrete count data like word frequencies in text classification.\n",
        "\n",
        "Bernoulli: Designed for binary features (0/1). Use for data with yes/no, presence/absence attributes.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ngD4K2wWZhkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpwGy60uXOuD",
        "outputId": "c7292df0-cfad-4a82-d7d9-ad601a41fa9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9933333333333333\n",
            "Support Vectors:\n",
            " [[5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ],
      "source": [
        "#Question 6: Write a Python program to:\n",
        "#● Load the Iris dataset\n",
        "#● Train an SVM Classifier with a linear kernel\n",
        "#● Print the model's accuracy and support vectors.\n",
        "#Answer\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "svm = SVC(kernel=\"linear\")\n",
        "svm.fit(X, y)\n",
        "\n",
        "print(\"Accuracy:\", svm.score(X, y))\n",
        "print(\"Support Vectors:\\n\", svm.support_vectors_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to:\n",
        "#● Load the Breast Cancer dataset\n",
        "#● Train a Gaussian Naïve Bayes model\n",
        "#● Print its classification report including precision, recall, and F1-score.\n",
        "#Answer\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDc-Laf3cZN2",
        "outputId": "34685a4d-c7c8-4ac2-dbab-e50725b06e1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        43\n",
            "           1       0.96      1.00      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.98      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to:\n",
        "#● Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best\n",
        "#C and gamma.\n",
        "#● Print the best hyperparameters and accuracy.\n",
        "\n",
        "#Answer:\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
        "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print('Best Params:', grid.best_params_)\n",
        "print('Accuracy:', grid.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ZmZsNBcuE8",
        "outputId": "455f0961-858c-4bd1-9d74-acdeaccfe9b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'C': 10, 'gamma': 0.01}\n",
            "Accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to:\n",
        "#● Train a Naïve Bayes Classifier on a synthetic text dataset (e.g. using\n",
        "#sklearn.datasets.fetch_20newsgroups).\n",
        "#● Print the model's ROC-AUC score for its predictions.\n",
        "#Answer:\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "data = fetch_20newsgroups(subset='all', categories=['sci.space', 'rec.autos'])\n",
        "X, y = data.data, data.target\n",
        "\n",
        "vectorizer = CountVectorizer(binary=False)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# ROC-AUC\n",
        "y_prob = nb.predict_proba(X_test)[:,1]\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zGzJzSwdD0d",
        "outputId": "8fd8b91f-8dce-4989-e22a-aaf99cd8787c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.9971941638608306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a company that handles\n",
        "email communications.\n",
        "Your task is to automatically classify emails as Spam or Not Spam. The emails may\n",
        "contain:\n",
        "● Text with diverse vocabulary\n",
        "● Potential class imbalance (far more legitimate emails than spam)\n",
        "● Some incomplete or missing data\n",
        "Explain the approach you would take to:\n",
        "● Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "● Choose and justify an appropriate model (SVM vs. Naïve Bayes)\n",
        "● Address class imbalance\n",
        "● Evaluate the performance of your solution with suitable metrics\n",
        "And explain the business impact of your solution\n",
        "\n",
        "Answer:\n",
        "Preprocessing: Vectorize text using methods like TF-IDF or CountVectorizer. Handle missing values by imputing with empty strings or dropping incomplete samples if needed.\n",
        "\n",
        "Model Choice: Start with Naïve Bayes (good for text and fast with high-dimensional data), but also try SVM for potentially higher accuracy. Naïve Bayes excels with text and imbalanced data; SVM needs more resources.\n",
        "\n",
        "Class Imbalance: Use resampling (e.g., SMOTE, oversample spam, or undersample non-spam), or adjust class weights ('class_weight' in SVM).\n",
        "\n",
        "Evaluation: Use metrics like Precision, Recall, F1-score, and ROC-AUC (not just accuracy) to judge performance—critical when legitimate emails outnumber spam.\n",
        "\n",
        "Business Value: Accurate spam detection saves user time, reduces risk of fraud/phishing, and improves overall email system reliability. Automated classification enables scalable monitoring and protects company reputation."
      ],
      "metadata": {
        "id": "L5f9TKUGdqsE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff91ed0e",
        "outputId": "e595a3c0-b9d3-409c-e41c-a2b24926138a"
      },
      "source": [
        "# Create a dummy emails.csv for demonstration\n",
        "data = {'text': ['This is a legitimate email.', 'Buy now and get free shipping!', 'Another important message.', 'Claim your prize today!'],\n",
        "        'label': ['not spam', 'spam', 'not spam', 'spam']}\n",
        "df_dummy = pd.DataFrame(data)\n",
        "df_dummy.to_csv('emails.csv', index=False)\n",
        "\n",
        "print(\"Dummy 'emails.csv' created.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy 'emails.csv' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# 1. Data loading (assume a CSV with columns 'text', 'label')\n",
        "df = pd.read_csv('emails.csv')\n",
        "\n",
        "# 2. Preprocessing: Handle missing values\n",
        "df['text'] = df['text'].fillna('')\n",
        "df['label'] = df['label'].fillna('not spam')\n",
        "\n",
        "# 3. Encode labels: spam=1, not spam=0\n",
        "df['label_num'] = (df['label'] == 'spam').astype(int)\n",
        "\n",
        "# 4. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label_num'], test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Text vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# 6. Handle class imbalance using class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.array([0,1]), y=y_train)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# 7. Model training with SVM (linear kernel)\n",
        "clf = SVC(kernel='linear', class_weight=class_weight_dict, probability=True)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# 8. Predictions\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "# 9. Evaluation\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['Not Spam', 'Spam']))\n",
        "\n",
        "# Optional: Probability outputs, ROC curve, etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EsM_-5mfZSv",
        "outputId": "0a9e85dc-3523-4662-8c16-6b2626cadb57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[0 0]\n",
            " [1 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Not Spam       0.00      0.00      0.00       0.0\n",
            "        Spam       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yt6mrmNfmbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}