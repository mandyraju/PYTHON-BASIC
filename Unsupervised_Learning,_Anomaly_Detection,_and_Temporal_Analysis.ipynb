{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Question 1 : What is Dimensionality Reduction? Why is it important in machine learning?\n",
        "\n",
        "Answer: Dimensionality reduction is the process of transforming data from a high-dimensional feature space to a lower-dimensional space while retaining as much of the important structure (signal/variance or class-separating information) as possible.\n",
        "\n",
        "It matters because high-dimensional data increases computational cost, exacerbates the curse of dimensionality (sparser data, unreliable distance measures), and heightens overfitting risk; reducing dimensions improves model generalization, speed, storage, interpretability, and enables 2D/3D visualization for exploration. In practice, it helps remove redundant and noisy features, stabilize distance-based methods\n",
        "\n",
        "Question 2: Name and briefly describe three common dimensionality reduction\n",
        "techniques..\n",
        "\n",
        "Answer: Principal Component Analysis (PCA): A linear projection method that finds orthogonal directions (principal components) capturing maximal variance; used for compression, denoising, and preprocessing before learning.​\n",
        "\n",
        "t‑SNE (t‑Distributed Stochastic Neighbor Embedding): A nonlinear manifold technique optimized for 2D/3D visualization that preserves local neighborhood structure to reveal clusters; not ideal as a preprocessing step for downstream models.​\n",
        "\n",
        "UMAP (Uniform Manifold Approximation and Projection): A fast nonlinear manifold method preserving both local and more global structure, scalable to large datasets, useful for visualization and sometimes as a feature transform.\n",
        "\n",
        "Question 3: What is clustering in unsupervised learning? Mention three popular clustering algorithms.\n",
        "\n",
        "Answer: Clustering is an unsupervised learning task that groups samples so that items within a cluster are more similar to each other than to items in other clusters, without using labels; similarity is defined by a distance or density notion appropriate to the data and objective. It is used for structure discovery, segmentation, compression, anomaly pre-filtering, and exploratory data analysis across domains such as marketing (customer segments), biology (cell types), and information retrieval (document/topic groups).\n",
        "\n",
        "K-Means: partitions data into K clusters by minimizing within-cluster variance; efficient and widely used, but assumes roughly spherical clusters and requires K chosen in advance (Elbow/Silhouette aids selection).​\n",
        "\n",
        "DBSCAN: density-based clusters discovered from core points and their neighborhoods; can find arbitrarily shaped clusters and marks noise explicitly, but needs density parameters (eps, minPts) tuned to data scale.​\n",
        "\n",
        "Agglomerative hierarchical clustering: bottom-up merges using a linkage criterion (single, complete, average, Ward) to produce a dendrogram, enabling multi-scale cluster selection and not requiring K upfront until cutting the tree\n",
        "\n",
        "Question 4: Explain the concept of anomaly detection and its significance.\n",
        "\n",
        "Answer:\n",
        "Anomaly detection is the identification of observations, events, or patterns that deviate significantly from the normal behavior of a system or dataset, often signaling fraud, faults, intrusions, safety risks, or data quality problems.\n",
        "\n",
        "Concept:\n",
        "\n",
        "Definition and goal: detect instances that do not conform to an established notion of normality; this may be called outlier, novelty, or deviation detection depending on whether anomalies were present in training data.​\n",
        "\n",
        "Anomaly types: point anomalies (an individual observation is extreme), contextual anomalies (normal generally but abnormal in a specific context like time/season), and collective anomalies (a sequence or group is anomalous even if members aren’t individually extreme).​\n",
        "\n",
        "Significance:\n",
        "\n",
        "Fraud and risk: credit card fraud, account takeover, money laundering, insurance abuse; rapid anomaly detection reduces direct financial loss and chargebacks.​\n",
        "\n",
        "Cybersecurity and IT/observability: intrusion and malware detection, DDoS spikes, service latency/SLA breaches, error-rate anomalies in logs/metrics that indicate incidents to triage quickly.​\n",
        "\n",
        "Industrial/IoT and healthcare: sensor drifts, vibration anomalies indicating equipment failure; physiological or lab value outliers flagging clinical deterioration or data-entry errors\n",
        "\n",
        "Question 5: List and briefly describe three types of anomaly detection techniques.\n",
        "\n",
        "Answer:\n",
        "Statistical methods: Model normal data distribution (e.g., Gaussian, robust z‑scores) and flag points with low likelihood or extreme deviation, effective when distributional assumptions hold.​\n",
        "\n",
        "Distance/Density-based methods: Use distances or neighborhood density to flag isolated points (e.g., kNN distance, Local Outlier Factor), well-suited when anomalies are far from dense regions.​\n",
        "\n",
        "Model-based/Representation methods: Learn a model of normality and flag high reconstruction error or low predicted probability (e.g., PCA reconstruction, one‑class SVM, autoencoders), flexible for complex data manifolds.\n",
        "\n",
        "Question 6: What is time series analysis? Mention two key components of time series data.\n",
        "\n",
        "Answer:\n",
        "Time series analysis is the statistical and analytical study of data points collected or recorded at sequential and usually equally spaced time intervals. Its aim is to uncover underlying patterns, forecast future values, detect anomalies, and understand how temporal structures such as trends and recurring cycles affect behavior over time.​\n",
        "\n",
        "Two key components:\n",
        "\n",
        "Trend: The long-term movement in the time series, which could be upward, downward, or flat, and reflects persistent change over periods longer than seasonal cycles (e.g., increasing sales year over year).​\n",
        "\n",
        "Seasonality: Regular, fixed-frequency patterns linked to calendar intervals, such as daily temperature changes, weekly website visits, or annual sales cycles.\n",
        "\n",
        "\n",
        "Question 7: Describe the difference between seasonality and cyclic behavior in time series.\n",
        "\n",
        "Answer:\n",
        "Seasonality and cyclic behavior are both recurring patterns in time series data, but they differ fundamentally in their regularity, cause, and predictability:\n",
        "\n",
        "Seasonality\n",
        "Definition: Seasonality is a pattern of fluctuations that repeats at a fixed, known interval due to calendar-related or external periodic influences (e.g., months, quarters, days of the week).​\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "Always has a constant and predictable period (e.g., every 12 months, once a week).\n",
        "\n",
        "Driven by factors like holidays, weather, or business cycles tied to the calendar.\n",
        "\n",
        "Examples include higher ice cream sales every summer or increased shopping activity every December.\n",
        "\n",
        "The timing and frequency of peaks and troughs do not change—seasonal effects are strictly regular and associated with the calendar.​\n",
        "\n",
        "Cyclic Behavior\n",
        "Definition: Cyclic behavior also involves up-and-down movements in a time series, but these cycles do not have a fixed, known period. Instead, the length and amplitude of each cycle can change depending on broader, often economic or systemic, forces.​\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "Cycles are not defined by the calendar; their durations and intensities vary.\n",
        "\n",
        "Often arise from business, economic, or system-driven factors (e.g., business booms and recessions).\n",
        "\n",
        "Peaks and troughs are less predictable, and the average duration of one cycle is generally much longer and more variable than seasonal intervals.\n",
        "\n",
        "Examples include economic expansions and contractions, with cycles lasting several years and both their timing and magnitude subject to change.\n",
        "\n"
      ],
      "metadata": {
        "id": "h4QZVwqLkhqm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keI57BxJkeVP",
        "outputId": "9ffbd99b-e92d-4a91-d137-c6105166d55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster centers:\n",
            " [[-0.21814896  1.14246759]\n",
            " [-1.04793262 -1.24307863]\n",
            " [ 1.26608158  0.10061104]]\n",
            "Cluster size distribution: [100 100 100]\n",
            "Inertia (sum of squared distances): 39.06864466333185\n"
          ]
        }
      ],
      "source": [
        "#Question 8: Write Python code to perform K-means clustering on a sample dataset.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate synthetic sample data with 3 clusters\n",
        "X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=1.5, random_state=42)\n",
        "\n",
        "# Scale for better clustering\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit K-means model\n",
        "kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
        "labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "print(\"Cluster centers:\\n\", kmeans.cluster_centers_)\n",
        "print(\"Cluster size distribution:\", np.bincount(labels))\n",
        "print(\"Inertia (sum of squared distances):\", kmeans.inertia_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: What is inheritance in OOP? Provide a simple example in Python.\n",
        "\n",
        "#Answer\n",
        "''' Inheritance is an object-oriented programming principle in\n",
        "which a new class (child/subclass) can use, extend, or override the properties\n",
        " and methods of another class (parent/superclass),\n",
        " promoting code reuse and clarity by modeling “is-a” relationships.'''\n",
        " #Example\n",
        "\n",
        "class Animal:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "    def speak(self):\n",
        "        return \"Some generic sound\"\n",
        "\n",
        "class Dog(Animal):\n",
        "    def speak(self):\n",
        "        return f\"{self.name} says Woof!\"\n",
        "\n",
        "class Cat(Animal):\n",
        "    def speak(self):\n",
        "        return f\"{self.name} says Meow!\"\n",
        "\n",
        "d = Dog(\"Bruno\")\n",
        "c = Cat(\"Luna\")\n",
        "print(d.speak()) # Output: Bruno says Woof!\n",
        "print(c.speak()) # Output: Luna says Meow!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gytw-7RGoS_Z",
        "outputId": "3a62866a-daf0-4540-b3ef-2d56ec8b8edc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bruno says Woof!\n",
            "Luna says Meow!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How can time series analysis be used for anomaly detection?\n",
        "\n",
        "Answer:\n",
        "Time series analysis enables anomaly detection by modeling expected temporal patterns (trend, seasonality, cycles) and flagging data points or intervals that significantly diverge from these learned structures. Approaches include:​\n",
        "\n",
        "Decomposition: Break time series into components (trend, seasonality, residual/noise) and detect outliers in the residuals after accounting for predictable effects.​\n",
        "\n",
        "Forecasting models: Use ARIMA, SARIMA, Prophet, or machine learning models to generate predictions and highlight deviations beyond confidence intervals.\n",
        "\n",
        "Window-based learning: Apply Isolation Forest, one-class SVM, autoencoders, or deep anomaly detectors on rolling windows or features engineered from time series.​\n",
        "\n",
        "This process is critical for early detection of operational failures, fraud, system errors, or unexpected events, powering alerts, interventions, and proactive business decisions in domains like IT, IoT, healthcare, energy, and manufacturing."
      ],
      "metadata": {
        "id": "E_QRP_S-n62z"
      }
    }
  ]
}